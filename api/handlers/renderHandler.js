// Render Handler - Handles both fastrack and accurate modes
// Separate proxy handler for render operations

import { GoogleGenerativeAI } from '@google/generative-ai';

// Initialize Gemini AI
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');

export async function handleRenderFastrack(action, data) {
  console.log('[Render Handler] handleRenderFastrack called with:', { action, dataKeys: Object.keys(data) });
  const { base64Sketch, base64Material, additionalDetails } = data;
  
  if (!base64Sketch) {
    throw new Error('Missing base64Sketch for render fastrack');
  }

  // Get base prompt from environment variable
  const basePrompt = process.env.RENDER_FASTRACK_KEY;
  
  if (!basePrompt) {
    throw new Error('RENDER_FASTRACK_KEY environment variable is not configured');
  }
  
  // Use only the environment variable base prompt (no user details)
  const finalPromptText = basePrompt;
  
  console.log('[Render Handler] Using only RENDER_FASTRACK_KEY prompt, length:', finalPromptText.length);

  // Clean base64 data
  const cleanBase64 = base64Sketch.replace(/^data:image\/[a-z]+;base64,/, '');
  const cleanMaterialBase64 = base64Material ? base64Material.replace(/^data:image\/[a-z]+;base64,/, '') : null;

  // Get the model
  const model = genAI.getGenerativeModel({ 
    model: "gemini-2.5-flash-image-preview" 
  });

  // Generate content with image generation config
  const result = await model.generateContent({
    contents: [{
      role: "user",
      parts: [
        { text: finalPromptText },
        {
          inlineData: {
            mimeType: "image/png",
            data: cleanBase64
          }
        },
        // Add material image if provided
        ...(cleanMaterialBase64 ? [{
          inlineData: {
            mimeType: "image/png",
            data: cleanMaterialBase64
          }
        }] : [])
      ]
    }],
    generationConfig: {
      responseMimeType: "image/png",
      responseModalities: ["IMAGE", "TEXT"]
    }
  });

  const response = await result.response;
  
  // Extract the generated image data
  const generatedImage = response.candidates?.[0]?.content?.parts?.find(
    part => part.inlineData && part.inlineData.mimeType?.startsWith('image/')
  );

  if (!generatedImage?.inlineData?.data) {
    throw new Error('No image generated by Gemini API');
  }

  const imageData = generatedImage.inlineData.data;

  // Return in format expected by client
  return {
    success: true,
    mode: "Render Fastrack",
    model_used: "render-ai-v2",
    enhanced_prompt: additionalDetails && additionalDetails.trim() 
      ? `Fashion sketch to realistic render. Additional requirements: ${additionalDetails.trim()}`
      : "Fashion sketch to realistic render",
    output: [{
      type: "image_generation_call",
      result: imageData,
      enhanced_description: additionalDetails && additionalDetails.trim()
        ? `Professional fashion render generated. Custom requirements: ${additionalDetails.trim()}`
        : "Professional fashion render generated"
    }],
    message: "Fashion render complete",
    imageDimensions: {
      width: 1024,
      height: 1536,
      aspectRatio: 1024 / 1536
    }
  };
}

export async function handleRenderAccurate(action, data) {
  console.log('[Render Handler] handleRenderAccurate called with:', { action, dataKeys: Object.keys(data) });
  const { base64Sketch, base64Material, additionalDetails } = data;
  
  if (!base64Sketch) {
    throw new Error('Missing base64Sketch for render accurate');
  }

  // For accurate mode, use OpenAI (implement as needed)
  // This is a placeholder - implement actual OpenAI call
  throw new Error('Render accurate mode not implemented yet');
}
